{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T01:50:04.839278Z",
     "start_time": "2020-07-15T01:49:59.792721Z"
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import math\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV,ParameterGrid,cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold,learning_curve,KFold\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "from sklearn.feature_selection import f_regression, mutual_info_regression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# 导入算法库\n",
    "from sklearn.linear_model import LinearRegression,Ridge,LassoCV,BayesianRidge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost.sklearn import XGBClassifier,XGBRegressor\n",
    "# import xgboost as xgb\n",
    "# from xgboost import plot_importance\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from random import shuffle\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import svm\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set_style('whitegrid')\n",
    "from matplotlib.font_manager import * \n",
    "plt.style.use('ggplot')          # 配色\n",
    "matplotlib.rcParams['figure.figsize'] = [20, 6] # for square canvas\n",
    "# sns.set(font='SimHei')  # 解决Seaborn中文显示问题\n",
    "pd.set_option('display.max_colwidth', 500)       # 设置字符串显示长度\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from sklearn.impute import SimpleImputer\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "#指定默认字体\n",
    "myfont = FontProperties(fname='./fonts/simhei.ttf') \n",
    "matplotlib.rcParams['font.sans-serif'] = ['SimHei'] \n",
    "matplotlib.rcParams['font.family']='sans-serif'\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T01:50:05.405155Z",
     "start_time": "2020-07-15T01:50:04.841237Z"
    }
   },
   "outputs": [],
   "source": [
    "data=pd.read_pickle('./data/diag_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-15T01:50:05.491092Z",
     "start_time": "2020-07-15T01:50:05.407474Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "阳性体征    174570\n",
       "疾病诊断     27633\n",
       "Name: 诊断类型, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "157824"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(202203, 19)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.诊断类型.value_counts()\n",
    "sum(data.病人ID.duplicated())\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.786Z"
    }
   },
   "outputs": [],
   "source": [
    "data_ino=pd.read_csv('./data/Medical_INO_details_Information.csv',encoding='gbk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.789Z"
    }
   },
   "outputs": [],
   "source": [
    "data.shape\n",
    "data_ino.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.791Z"
    }
   },
   "outputs": [],
   "source": [
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在Excel（后面发现Excel未完全显示）中观察体检数据表INO，总结以下：\n",
    "- 1. 诊断标志9 表示**无异常**，只有一个编号759230的体检记录中 一个男的异常提示被记录为h（其他为空白）， 但是阳性为0， 考虑为录入失误, 将'诊断标志'修正为4\n",
    "  2. 诊断标志4 表示**异常**(h/阳性),除了三个：其中一个编号820410的体检记录， 一个男的异常记录为z，阳性为1， 考虑录入失误， 将'异常提示'修正为h \n",
    "  3. 诊断标志3 表示**无异常**(z/心率)   考虑转化为0\n",
    "  4. 诊断标志2 表示**异常**(h)\n",
    "  5. 诊断标志1 表示**异常**(l)/**心率**（无具体数值，并且阳性特征全部为0）\n",
    "  6. 诊断标志0 表示**无异常**(空白)，除了一个编号759224的体检记录,异常记录为'h',阳性为0， 录入失误， 将诊断标志修正为**2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.827Z"
    }
   },
   "outputs": [],
   "source": [
    "data_ino.groupby('诊断标志')['异常提示'].value_counts().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.832Z"
    }
   },
   "outputs": [],
   "source": [
    "data_ino.loc[759224, '诊断标志'] = 2                 # 修正 #6\n",
    "\n",
    "data_ino.at[(data_ino.异常提示 == 'z')&(data_ino.诊断标志 == 4), '异常提示'] = 'h' # 修正 #2\n",
    "\n",
    "data_ino.loc[759230, '诊断标志'] = 4              # 修正 #1\n",
    "\n",
    "data_ino['诊断标志'] = np.floor(data_ino['诊断标志'])\n",
    "\n",
    "data_ino['诊断标志'] = data_ino.apply(lambda x: 0 if x['诊断标志'] == 3 or x['诊断标志'] > 4 else x['诊断标志'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.835Z"
    }
   },
   "outputs": [],
   "source": [
    "data_ino['诊断标志'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.838Z"
    }
   },
   "outputs": [],
   "source": [
    "data_ino.groupby('异常标志')['异常提示'].value_counts().unstack()            ## 异常标志这个 0 值有点问题， 不可信\n",
    "# data_ino[(data_ino.异常提示 == 'z')&(data_ino.异常标志 == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.840Z"
    }
   },
   "outputs": [],
   "source": [
    "temp_ino = data_ino\n",
    "# 函数 填充'诊断标志'为NaN的情况 为 透视表 做准备\n",
    "def fill_labels(df):\n",
    "    if pd.isnull(df['诊断标志']):\n",
    "        if pd.isnull(df['正常结果']):\n",
    "            if df['异常提示'] == 'z':\n",
    "                return 0\n",
    "            elif df['异常提示'] == '+' or df['异常提示'] == 'h':\n",
    "                return 2\n",
    "            elif df['异常提示'] == '-' or df['异常提示'] == 'l':\n",
    "                return 1\n",
    "        else:\n",
    "            return 0        # 正常全为0\n",
    "    else:\n",
    "        return df['诊断标志']\n",
    "# temp_ino.at[temp_ino['诊断标志'].isnull() & -(temp_ino['正常结果'].isnull()) & (temp_ino['', '诊断标志'] = 0\n",
    "temp_ino.groupby('诊断标志')['异常提示'].value_counts().unstack()                     # 处理前\n",
    "temp_ino['诊断标志'] = temp_ino.apply(fill_labels, axis=1)\n",
    "temp_ino.groupby('诊断标志')['异常提示'].value_counts().unstack()                      # 处理后"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是 比如9.0 或者其他值，并且'异常提示'为NaN的 没有上榜。。。 比如'鼻','心率'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.860Z"
    }
   },
   "outputs": [],
   "source": [
    "# data_ino.groupby(['病人ID'])\n",
    "combined_ino = temp_ino.pivot_table(values='诊断标志', index='病人ID', columns='项目名称') #, aggfunc=lambda x : (label_Dict[x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.861Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in combined_ino.columns:\n",
    "    combined_ino[col].value_counts()\n",
    "# combined_ino['血压'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "完善血压 心率 年龄 性别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "血压需要处理数值\n",
    "- 高血压： 18岁成人，收缩压 >= 140 **或** 舒张压 >= 90 （单位mmHg\n",
    "- 低血压： 血压低于**90/60**mmHG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.893Z"
    }
   },
   "outputs": [],
   "source": [
    "data_press = data_ino.loc[data_ino['项目名称'] == '血压', ['病人ID', '检查结果']]\n",
    "# pattern_pa\n",
    "def fill_press(df):\n",
    "    pattern_press = re.compile(r\"(?P<收缩压>\\d+)/(?P<舒张压>\\d+)\")\n",
    "#     res = \n",
    "# data_press.apply()\n",
    "pa = r\"(\\d+)/(\\d+)\"\n",
    "pa_name = r\"(?P<收缩压>\\d+)/(?P<舒张压>\\d+)\"\n",
    "# data_press[['收缩压', '舒张压']] = data_press.检查结果.str.extract(pa)\n",
    "press_re = data_press.检查结果.str.extract(pa_name)                                   # extract() 与 extractall() \n",
    "press_res = pd.concat([data_press, press_re], axis=1).set_index('病人ID')                           # 前者找第一个匹配 后者找全部匹配（所以有match）\n",
    "press_res.drop(['检查结果'], axis=1, inplace=True)\n",
    "# data_press"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "心率的 诊断标志有问题。。。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.913Z"
    }
   },
   "outputs": [],
   "source": [
    "# sum(res.isnull().sum())\n",
    "# res == combined_ino_temp\n",
    "# res.isnull()\n",
    "# res.loc[res.index.isin(['3000045556']), 'ABO血型'] = 2\n",
    "# res\n",
    "\n",
    "# combined_ino_res['心率'].value_counts()#.at[:, '体检总结'] = data_report['体检总结']                #['肌酐(Cr)'] #体检总结\n",
    "# sample = combined_ino_temp.sample(1) #.index.is_unique\n",
    "# data_report = data_report.drop_duplicates()\n",
    "# data_report.index.is_unique\n",
    "# sample\n",
    "def heart_beat_float(df):\n",
    "#     pattern = re.compile(r\"*?(\\d+)*?\")\n",
    "#     df['检查结果'] = float(re.match(pattern, df['检查结果'].strip(' ')))\n",
    "#     df['检查结果'].strip(' ')\n",
    "    if type(df['检查结果']) != float:\n",
    "        df['检查结果'].strip(' ')\n",
    "    return df\n",
    "        \n",
    "# beat_pattern = re.compile(r\"()\")\n",
    "heart_beat = data_ino.loc[data_ino['项目名称'] == '心率', ['病人ID', \"检查结果\"]].set_index('病人ID')\n",
    "# heart_beat = heart_beat.apply(heart_beat_float, axis=0)\n",
    "# heart_beat.drop(type(heart_beat['检查结果'])!=float)\n",
    "# type(heart_beat['检查结果'])!=float\n",
    "# heart_beat.set_index('病人ID')\n",
    "#  利用掩码查看异常值 发现有奇怪文本“拒绝检查” 和 6 \"61 61\" \"正常\" 这样的异常数字\n",
    "mask = heart_beat.loc[:, ['检查结果']].applymap(lambda x: isinstance(x, str) and (len(x) == 2 or len(x) == 3) and x.isdigit()).values\n",
    "# mask = heart_beat.loc[:, ['检查结果']].applymap(lambda x: isinstance(x, int)).values\n",
    "heart_beat.loc[:, ['检查结果']] = heart_beat.loc[:, ['检查结果']].applymap(lambda x: float(x) if isinstance(x, str) and (len(x) == 2 or len(x) == 3) and x.isdigit() else np.nan)\n",
    "\n",
    "beat_press = pd.merge(heart_beat[mask], press_res, on='病人ID', how='left')\n",
    "beat_press.rename(columns={'检查结果':\"心率值\"}, inplace=True)\n",
    "# beat_press.drop_duplicates(inplace=True)\n",
    "beat_press = beat_press[~beat_press.index.duplicated(keep='first')]            # 删去重复的病人ID（index)\n",
    "sum(beat_press.index.duplicated())\n",
    "beat_press.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.915Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.DataFrame([[1, None], [5, 4], [4, 4]], columns=['a', 'b'])\n",
    "# def apply_test(input):\n",
    "#     if input.a == 1:\n",
    "#         input['b'] = 3\n",
    "#     return input\n",
    "# def test2(input):\n",
    "#     if input.isnull().sum() > 0:\n",
    "#         df.drop(input)\n",
    "#     return input\n",
    "# sum(df.isnull().sum())\n",
    "# # test_res = df.apply(test2, result_type='reduce')\n",
    "# # sum(test_res.isnull().sum())\n",
    "# # sum(df.isnull().sum())\n",
    "# df\n",
    "# test_res\n",
    "\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.919Z"
    }
   },
   "outputs": [],
   "source": [
    "data_report = data_ino[['病人ID', '年龄', '性别' ,'体检总结']].copy().set_index('病人ID')\n",
    "# data_report = data_report.drop_duplicates()            ## 去重没有用？？？ 病人ID依然重复\n",
    "data_report = data_report[~data_report.index.duplicated(keep='first')]\n",
    "\n",
    "combined_ino_temp = combined_ino.copy()\n",
    "combined_ino_temp = pd.merge(combined_ino_temp, data_report, on='病人ID', how='left', left_index=True, sort=False)\n",
    "\n",
    "pattern_UP = re.compile(r' (?P<项目名称>[^↓\\n]+?)：[^↓]+? ↑')     # 非贪婪匹配 ? ; 匹配1+次 + ; 匹配非符号[^]\n",
    "pattern_DOWN = re.compile(r' (?P<项目名称>[^↑\\n]+?)：[^↑]+? ↓')     # 非贪婪匹配 ? ; 匹配1+次 + ; 匹配非符号[^]\n",
    "\n",
    "def fill_Combined_re(combined_ino, temp, pattern_UP=pattern_UP, pattern_DOWN=pattern_DOWN):\n",
    "#     pattern_UP = r' (?P<项目名称>[^↓\\n]+?)：[^↓]+? ↑'\n",
    "#     item_UP = combined_ino.体检总结.str.extractall(pattern_UP)\n",
    "#     list_UP = list(item_UP.项目名称.map(lambda x: x.strip()))\n",
    "    combined_ino\n",
    "    UP = pattern_UP.findall(str(combined_ino.体检总结))\n",
    "    list_UP = list(map(lambda x: x.strip(), UP))\n",
    "    for item in list_UP:\n",
    "        if item in temp.columns:\n",
    "#             if combined_ino[item] != 2:\n",
    "#                 print('病人: ', item, \" 上升值 :\", combined_ino[item])\n",
    "#                 print(item, ':', combined_ino.item)\n",
    "#             print(item)\n",
    "            combined_ino[item] = 2\n",
    "#             temp.loc[temp.index.isin([combined_ino.index[0]]), item] = 2\n",
    "#         else:\n",
    "#             print(item)\n",
    "    \n",
    "#     pattern_DOWN = r' (?P<项目名称>[^↑\\n]+?)：[^↑]+? ↓'\n",
    "#     item_DOWN = combined_ino.体检总结.str.extractall(pattern_DOWN)\n",
    "#     list_DOWN = list(item_DOWN.项目名称.map(lambda x: x.strip()))\n",
    "    DOWN = pattern_DOWN.findall(str(combined_ino.体检总结))\n",
    "    list_DOWN = list(map(lambda x: x.strip(), DOWN))\n",
    "    for item in list_DOWN:\n",
    "        if item in temp.columns:\n",
    "            temp_value = combined_ino[item]\n",
    "            combined_ino[item] = 1\n",
    "#             if temp_value != 1:\n",
    "#                 print('病人: ', item, \" 下降值 :\", combined_ino[item])\n",
    "#             temp.loc[temp.index.isin([combined_ino.index[0]]), item] = 1\n",
    "#         else:\n",
    "#             print(item)\n",
    "    return combined_ino\n",
    "\n",
    "# combined_ino_temp = combined_ino_temp.sample(1000)\n",
    "sum(combined_ino_temp.isnull().sum())\n",
    "combined_ino_res = combined_ino_temp.copy()\n",
    "res = combined_ino_temp.apply(fill_Combined_re, temp=combined_ino_res, axis=1)  #  apply 到每一行\n",
    "sum(combined_ino_temp.isnull().sum())\n",
    "sum(combined_ino_res.isnull().sum())\n",
    "sum(res.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试正则表达式的正确性（似乎会漏掉NAN的数据，因为我感觉不止三个）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.933Z"
    },
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# pattern_UP = r' (?P<项目名称>[^↓\\n]+?)：[^↓]+? ↑'\n",
    "# item_UP = test_src.str.extractall(pattern_UP)\n",
    "# pattern_DOWN = r' (?P<项目名称>[^↑\\n]+?)：[^↑]+? ↓'\n",
    "# item_DOWN = test_src.str.extractall(pattern_DOWN)\n",
    "# print(item_UP)\n",
    "# print(item_DOWN)\n",
    "# pattern = re.compile(r' [^↓\\n]+?：[^↓]+? ↑')\n",
    "for i in range(111110):\n",
    "    test_src = res.sample(1)\n",
    "    pattern = re.compile(r' (?P<项目名称>[^↓\\n]+?)：[^↓]+? ↑')     # 非贪婪匹配 ? ; 匹配1+次 + ; 匹配非符号[^]\n",
    "    pattern_res = pattern.findall(str(test_src.体检总结))\n",
    "    # pattern_res = pattern.findall(test_src.values[0])\n",
    "    for item in list(map(lambda x: x.strip(), pattern_res)):\n",
    "        if item in test_src.columns:\n",
    "            if test_src[item].values != 2:\n",
    "                print(test_src[item])            \n",
    "# type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.936Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.merge(res, beat_press, on='病人ID', how='left')\n",
    "# train_df\n",
    "\n",
    "combined_res = train_df.copy()\n",
    "patient_num = combined_res.shape[0]       # 样本总数\n",
    "def cut(df, cutoff):\n",
    "    total_row = df.shape[0]\n",
    "    for col in df.columns:\n",
    "        cnt = df[col].count()\n",
    "        if (cnt / total_row) < cutoff:\n",
    "            df.drop(col, axis=1, inplace=True) \n",
    "#         elif(cnt / total_row)\n",
    "# combined_res.apply(lambda x : x.isnull().sum()).plot()\n",
    "# cut(combined_res, 0.5)                   # 缺失值2/3以上就删掉\n",
    "combined_res.dropna(axis=1, thresh=patient_num/3, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.938Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.940Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.plot([-1,2,-5,3]) \n",
    "# plt.title(u'Linux公社的网址是www.linuxidc.com',fontproperties=myfont) \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.942Z"
    }
   },
   "outputs": [],
   "source": [
    "import missingno\n",
    "missingno.matrix(combined_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.943Z"
    }
   },
   "outputs": [],
   "source": [
    "gender_dict = {'男':1, '女':0}\n",
    "combined_res['性别'] = combined_res['性别'].map(gender_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.945Z"
    }
   },
   "outputs": [],
   "source": [
    "combined_res.loc[:, ['心率值']].describe()              # 最小心率 最大心率惨不忍睹\n",
    "combined_res.loc[:, ['心率值']].median()            # 最小心率 最大心率惨不忍睹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看每一个项目的 值分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.958Z"
    }
   },
   "outputs": [],
   "source": [
    "imp_median = SimpleImputer(strategy=\"median\")                 # 使用中位数填充\n",
    "combined_temp = combined_res.drop(columns=['体检总结'], axis=1)\n",
    "combined_temp.loc[:, :] = imp_median.fit_transform(combined_temp)\n",
    "\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# combined_temp\n",
    "\n",
    "combined_temp.loc[:, '年龄'] = np.where(combined_temp.loc[:, '年龄']>100,  combined_temp.loc[:, '年龄'].median(), combined_temp.loc[:, '年龄'])\n",
    "combined_temp.loc[:, '心率值'] = np.where(combined_temp.loc[:, '心率值']>150,  combined_temp.loc[:, '心率值'].median(), combined_temp.loc[:, '心率值'])\n",
    "\n",
    "# 连续变量编码： 年龄：kmeans分箱， 心率： 等位分箱（数量相等）\n",
    "width_est = KBinsDiscretizer(n_bins=6, encode='ordinal', strategy='kmeans')          \n",
    "count_est = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='quantile')         \n",
    "age_dummies = combined_temp.loc[:, '年龄'].values.reshape(-1, 1) \n",
    "combined_temp.loc[:, '年龄'] = width_est.fit_transform(age_dummies)\n",
    "\n",
    "heart_dummies = combined_temp.loc[:, '心率值'].values.reshape(-1, 1)\n",
    "combined_temp.loc[:, '心率值'] = count_est.fit_transform(heart_dummies)\n",
    "\n",
    "# Onehot-encode 性别（无关离散变量）\n",
    "# gender_enc = OneHotEncoder()\n",
    "# gender_bin = combined_temp.loc[:, '性别'].values.reshape(-1, 1)\n",
    "# gender_mat = gender_enc.fit_transform(gender_bin).astype(int)\n",
    "# gender_mat.columns = ['男', '女']\n",
    "# gender_mat\n",
    "# combined_temp = pd.concat([combined_temp, gender_mat], axis=1)\n",
    "\n",
    "# # dummies\n",
    "# gender_bin = pd.get_dummies(combined_temp['性别'])\n",
    "# gender_bin.rename(columns={0:'男', 1:'女'}, inplace=True)\n",
    "# combined_temp = pd.concat([combined_temp, gender_bin], axis=1)\n",
    "\n",
    "# combined_temp = combined_temp.drop(columns=['性别'])         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算健康分数的数学模型\n",
    "参考金融风控领域的信用分的模型$^{【1】}$，评分卡的分值刻度通过将**分值**表示为**比率对数**的线性表达式:\n",
    "\n",
    "$$Score = A-B*log(odds )$$  其中，A为补偿，B为刻度，都为常数 \n",
    "\n",
    "$$odds = \\frac{p}{1-p}$$\n",
    "\n",
    "$$p = w_1X_1 + w_2X_2 + w_3X_3 +...+w_nX_n +b= W^{T}X+b$$\n",
    "\n",
    "其中$p$由Lasso线性回归模型（与岭回归类似）得到，范围[0, 1]，表示非健康的概率。引入违约翻倍系数PDO，即当 **$odds$**（非健康：健康比例)为两倍的时候，分数为$Score+PDO$：\n",
    "\n",
    "$$Score +PDO = A-B*log(2*odds)$$\n",
    "### 计算参数A，B\n",
    "   解两个方程，得$$B=\\frac{PDO}{ln(2)}$$, $$A = Score_0 + B*ln(odds_0)$$\n",
    "    \n",
    "   这里的 **$odds_0$** 为基准坏/好比例，这里取诊断结果表的阳性/阴性比例，得到$\\frac{19832}{25543}=0.776416$, \n",
    "    \n",
    "   $ln(odds_0) = -0.253066$ 设置**基准分$Score_0$为70，$PDO=20$**（这里可以自行调整，为了将大部分的分数限制在100分以内，我使用这个参数）代入得：\n",
    "   \n",
    "   $$B = 28.853900； A = 62.698058$$\n",
    "    \n",
    "引用【1】：[信用评分卡模型开发与应用](shichen.name/slide/20171115scorecard/#60)\n",
    "    \n",
    "    【2】：基于XGBOOST的用户信用评分建模_韩修龙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.981Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.decomposition import PCA          ## PCA 无监督降维得到新的正交特征矩阵，模型可解释性 差\n",
    "\n",
    "y_pred = KMeans(n_clusters=5).fit_predict(combined_temp)\n",
    "\n",
    "# cluster_dict = {}\n",
    "# for index, v in enumerate(y_pred):\n",
    "#     cluster_dict[combined_temp.columns[index]] = v\n",
    "\n",
    "pca = PCA(n_components=0.99)             # 不直接指定降维的维度，而指定降维后的主成分方差和 比例\n",
    "train_input = combined_temp.loc[:, combined_temp.columns]   # 取 输入\n",
    "pca.fit(train_input)\n",
    "print(pca.explained_variance_ratio_)  # 代表降维后的各主成分的方差值。方差值越大，则说明越是重要的主成分 \n",
    "print(pca.explained_variance_)        # 代表降维后的各主成分的方差值占总方差值的比例，这个比例越大，则越是重要的主成分。\n",
    "print(pca.n_components_)\n",
    "\n",
    "pca_res = pca.transform(train_input)\n",
    "# pca_res.columns\n",
    "\n",
    "# sum(combined_ino_res.isnull().sum())\n",
    "# # combined_ino_res == combined_ino_temp\n",
    "# combined_ino_temp.isnull().sum()\n",
    "\n",
    "# sample.get('总胆红素(TBIL)')                   # 验证OK\n",
    "# sample.get('总胆红素(TBIL)')                   # 验证OK\n",
    "# sample.columns              # 验证OK\n",
    "# combined_ino_temp.index.is_unique            # 病人ID重复 == \n",
    "\n",
    "# data_ino.info()\n",
    "# data_ino[(data_ino.项目代码 == 1004)]# & (data_ino.检查结果 == '阴性')]     # 同一个项目代码对应不同的 项目名称 所以 检查结果 和 异常提示 都不一样\n",
    "\n",
    "#data_ino[data_ino['项目名称'] == '血压']\n",
    "\n",
    "# test_src = res.sample(1)\n",
    "# # test_src.values[0]\n",
    "# test_src\n",
    "\n",
    "# # list(item_DOWN.项目名称.map(lambda x: x.strip()))\n",
    "# test_src.index\n",
    "# item_DOWN.index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "发现同样的**项目名称**居然对应不一样的**项目代码**， 同样的**项目代码** 对应两个**项目名称** =="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.994Z"
    }
   },
   "outputs": [],
   "source": [
    "data_ino.pivot_table(index=['项目代码', '项目名称'], columns='异常提示', values='诊断标志', aggfunc=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:58.997Z"
    }
   },
   "outputs": [],
   "source": [
    "data_ino_age = data_ino[['年龄', '病人ID', '性别']].copy()\n",
    "data_ino_age_temp = data_ino_age.rename(columns = {'年龄': 'age', '性别': 'gender'})\n",
    "data_ino_age_temp.loc[data_ino_age_temp.gender == '男', ['gender']] = 'male'               # sns 不支持中文，除非加载字体\n",
    "data_ino_age_temp.loc[data_ino_age_temp.gender == '女', ['gender']] = 'female'\n",
    "data_ino_age_temp = data_ino_age_temp.drop_duplicates()\n",
    "plt.figure(figsize=(20, 7))\n",
    "sns.violinplot(x='age', data=data_ino_age_temp, orient='h', y='gender', split=True, palette='Set2', fontproperties=myfont)\n",
    "plt.title('gender-age')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "男性最大197岁应该是录入错误"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:59.009Z"
    }
   },
   "outputs": [],
   "source": [
    "# age = data_ino[['病人ID', '年龄']].groupby(['病人ID'])\n",
    "data_ino_female = data_ino[data_ino.性别.isin([\"女\", ])]\n",
    "data_ino_male = data_ino[data_ino.性别.isin([\"男\", ])]\n",
    "age_female = data_ino_female[['年龄', '病人ID']]\n",
    "age_male = data_ino_male[['年龄', '病人ID']]\n",
    "# age_mask = age.duplicated()\n",
    "age_dup_female = age_female.drop_duplicates()\n",
    "age_dup_male = age_male.drop_duplicates()\n",
    "# age_dup = age_dup[['病人ID', '年龄']].value_counts()\n",
    "\n",
    "# age_dup_female.年龄.value_counts().sort_index().plot.bar(figsize = (20, 5))\n",
    "# age_dup_male_count = age_dup_male.年龄.value_counts().sort_index()\n",
    "# fig, axis1 = plt.subplots(1,1,figsize=(20,5))\n",
    "# age_dup_male_count['age'] = age_dup_male_count.index\n",
    "# age_dup_male_count['count'] = age_dup_male_count[age_dup_male_count['age']]\n",
    "# age_dup_male_count_df = age_dup_male_count.to_frame()\n",
    "# age_dup_male_count_df[age] = age_dup_male_count_df.index\n",
    "# sns.barplot(age_dup_male_count_df.index, age_dup_male_count_df.年龄, data = age_dup_male_count)\n",
    "g = sns.countplot(x='年龄', data = age_dup_male, palette='rainbow')\n",
    "# g.set_axis_labels(\"age\", \"count\")\n",
    "# plt.show()\n",
    "g1 = sns.countplot(x='年龄', data = age_dup_female, palette='ocean_r')\n",
    "# g1.set_axis_labels('age', 'count')\n",
    "# age_dup.年龄.value_counts()\n",
    "# age_dup_male"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 引入诊断结果，转化为有监督回归问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:59.023Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "disease_rate = data.groupby('诊断名称')['诊断类型'].value_counts().unstack().fillna(0)\n",
    "# 发病人数：kmeans分箱\n",
    "kmeans_bins = KBinsDiscretizer(n_bins=6, encode='ordinal', strategy='kmeans')    \n",
    "disease_col = disease_rate.loc[:, '疾病诊断'].values.reshape(-1, 1)\n",
    "\n",
    "disease_rate.loc[:, 'label'] = kmeans_bins.fit_transform(disease_col)\n",
    "disease_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在Excel（后面发现Excel未完全显示）中观察体检数据表INO，总结以下：\n",
    "- 1. 诊断标志9 表示**无异常**，只有一个编号759230的体检记录中 一个男的异常提示被记录为h（其他为空白）， 但是阳性为0， 考虑为录入失误, 将'诊断标志'修正为4\n",
    "  2. 诊断标志4 表示**异常**(h/阳性),除了三个：其中一个编号820410的体检记录， 一个男的异常记录为z，阳性为1， 考虑录入失误， 将'异常提示'修正为h \n",
    "  3. 诊断标志3 表示**无异常**(z/心率)   考虑转化为0\n",
    "  4. 诊断标志2 表示**异常**(h)\n",
    "  5. 诊断标志1 表示**异常**(l)/**心率**（无具体数值，并且阳性特征全部为0）\n",
    "  6. 诊断标志0 表示**无异常**(空白)，除了一个编号759224的体检记录,异常记录为'h',阳性为0， 录入失误， 将诊断标志修正为**2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标签：将诊断类型数为0的患者判断为健康，大于0的为非健康, 收缩压和舒展压的数值缺失较多"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:59.049Z"
    }
   },
   "outputs": [],
   "source": [
    "check_temp = data.groupby('病人ID')['诊断类型'].value_counts().unstack()\n",
    "check_temp.fillna(0, inplace=True)\n",
    "check_temp['label'] = np.where(check_temp['疾病诊断'] == 0, 0, 1)\n",
    "check_temp.drop(columns=['疾病诊断', '阳性体征'], axis=1, inplace=True)\n",
    "train_x = combined_temp.copy()\n",
    "# 把输入和label 合起来\n",
    "train_input = pd.merge(train_x, check_temp, on='病人ID', how='left')\n",
    "train_input.fillna(0, inplace=True)\n",
    "train_input['label'].value_counts()\n",
    "train_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "年龄之前的输入数据全部dummies化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:59.061Z"
    }
   },
   "outputs": [],
   "source": [
    "items = train_input.columns[:-6]\n",
    "#  全部取 整数部分\n",
    "floor_train = np.floor(train_input.loc[:, train_input.columns[:-6]])\n",
    "# floor_train = train_x.copy()\n",
    "# 对数据清洗 ，针对不同的情况 ： 正常、低、高进行dummies处理\n",
    "for item in items:\n",
    "#     floor_train.loc[:, item].value_counts()\n",
    "#  Series.index .values\n",
    "#     floor_train.loc[:, item].value_counts()\n",
    "    # 表示在各个检查项目出现的值， 并且根据情况进行 dummies化\n",
    "    index = floor_train.loc[:, item].value_counts().index\n",
    "    index = set(index)\n",
    "#     print(item, index)\n",
    "    \n",
    "    # 如果只有一个值 删除\n",
    "    if len(index) == 1 or len(index) > 4:\n",
    "        floor_train = floor_train.drop(columns = [item])  \n",
    "#     elif len(index) \n",
    "    elif index == {0, 4}:\n",
    "        floor_train[item] = np.where(floor_train[item] == 4, 1, 0)\n",
    "    # 4 2 都表示阳性\n",
    "    elif index == {0, 2, 4}:\n",
    "        floor_train[item] = np.where(floor_train[item] == 4, 2, floor_train[item])\n",
    "        floor_train[item] = np.where(floor_train[item] == 2, 1, 0)\n",
    "    #  4 这里重新赋值为2 其实也有阳性的意思 只能取片面意思\n",
    "    elif index == {0, 1, 2, 4}:\n",
    "        floor_train[item] = np.where(floor_train[item] == 4, 2, floor_train[item])\n",
    "        bins = pd.get_dummies(floor_train[item])\n",
    "        bins.rename(columns={0: item+'_正常', 1: item+'_低', 2: item+'_高'}, inplace=True)   \n",
    "        floor_train = pd.concat([floor_train, bins], axis=1)\n",
    "\n",
    "        floor_train = floor_train.drop(columns = [item])  \n",
    "    # 0 正常 1 低 2 高\n",
    "    elif index == {0, 1, 2}:\n",
    "        bins = pd.get_dummies(floor_train[item])\n",
    "        bins.rename(columns={0: item+'_正常', 1: item+'_低', 2: item+'_高'}, inplace=True)   \n",
    "        floor_train = pd.concat([floor_train, bins], axis=1)\n",
    "\n",
    "        floor_train = floor_train.drop(columns = [item])  \n",
    "\n",
    "# gender_bin = pd.get_dummies(combined_temp['性别'])\n",
    "# gender_bin.rename(columns={0:'男', 1:'女'}, inplace=True)   \n",
    "# combined_temp = pd.concat([combined_temp, gender_bin], axis=1)\n",
    "\n",
    "# combined_temp = combined_temp.drop(columns=['性别'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:59.062Z"
    }
   },
   "outputs": [],
   "source": [
    "floor_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:59.064Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_input['QRS'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上文中分箱的连续变量：年龄，心率值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:59.081Z"
    }
   },
   "outputs": [],
   "source": [
    "age_gender_HRate = train_input.loc[:, ['性别', '年龄',  '心率值'] ]\n",
    "# ss = StandardScaler()     # 根据方差来缩放，标准化\n",
    "mm = MinMaxScaler()         #根据极大极小值，归一化\n",
    "# X_train.loc[: ] = ss.fit_transform(X_train)\n",
    "age_gender_HRate.loc[: ] = mm.fit_transform(age_gender_HRate)\n",
    "age_gender_HRate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很好奇最后的结果和男女性别的关系。\n",
    "\n",
    "结果是，女性不健康（和之前的结论相反，之前认为样本男性年龄大于女性有关）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:59.092Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:59.094Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_train = train_input.loc[ :, train_input.columns[:-1] ]   # 取 输入\n",
    "X_train = pd.concat([floor_train, age_gender_HRate], axis=1)\n",
    "y = train_input.loc[:, 'label']\n",
    "\n",
    "model_lasso = LassoCV(alphas = [1, 0.1, 0.001, 0.0005]).fit(X_train, y) # 此处 alpha 为通常值 #fit 把数据套进模型里跑\n",
    "coef = pd.Series(model_lasso.coef_, index = X_train.columns)             # .coef_ 可以返回经过学习后的所有 feature 的参数。\n",
    "# 如果权值为 0 就是被筛选掉的 feature\n",
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")\n",
    "for c in coef.index:\n",
    "    print(c + \" coef :\" + str(coef[c]))\n",
    "imp_coef = pd.concat([coef.sort_values().head(12), \n",
    "                     coef.sort_values().tail(12)])                       #选头尾各10条，.sort_values() 可以将某一列的值进行排序。\n",
    "# matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "plt.figure(figsize=(20,15))\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Coefficients in the Lasso Model\")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测每一个样本不健康的概率，根据公式算出来最后的分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:59.104Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_res = model_lasso.predict(X_train)\n",
    "def calculate_score(prob):\n",
    "    A = 62.698058\n",
    "    B = 28.853900\n",
    "    if prob == 1:\n",
    "        return 100\n",
    "    return A -  B * math.log(prob / (1 - prob))\n",
    "score_list = list(map(calculate_score, predict_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:59.106Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))    # 指定画布尺寸\n",
    "axis = sns.distplot(a=score_list, color='g')\n",
    "axis.set_xlabel(u\"分数\")\n",
    "axis.set_ylabel('占比')\n",
    "plt.title(\"分数分布\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "普通的LR 模型无法归一化，同样的步骤 但是权值和预测结果都很大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:59.115Z"
    }
   },
   "outputs": [],
   "source": [
    "# linear_model = LinearRegression(normalize=True)\n",
    "# LR_model = linear_model.fit(X_train, y)\n",
    "# coef = pd.Series(LR_model.coef_, index = X_train.columns)             # .coef_ 可以返回经过学习后的所有 feature 的参数。\n",
    "# print(\"LR picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")\n",
    "# for c in coef.index:\n",
    "#     print(c + \" coef :\" + str(coef[c]))\n",
    "# imp_coef = pd.concat([coef.sort_values().head(12), \n",
    "#                      coef.sort_values().tail(12)])                       #选头尾各10条，.sort_values() 可以将某一列的值进行排序。\n",
    "# # matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "# plt.figure(figsize=(20,15))\n",
    "# imp_coef.plot(kind = \"barh\")\n",
    "# plt.title(\"Coefficients in the LR Model\")   \n",
    "# predict_res = LR_model.predict(X_train)\n",
    "# score_list = list(map(calculate_score, predict_res))\n",
    "\n",
    "# plt.figure(figsize=(20, 10))    # 指定画布尺寸\n",
    "# axis = sns.distplot(a=score_list, color='b')\n",
    "# axis.set_xlabel(u\"分数\")\n",
    "# axis.set_ylabel('占比')\n",
    "# plt.title(\"分数分布\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgbdt的模型比线性回归表现好一点，前者分数0.182 后者0.192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:59.127Z"
    }
   },
   "outputs": [],
   "source": [
    "linear_model = LinearRegression(normalize=True)\n",
    "ridge_model = Ridge()\n",
    "gbdt_model = GradientBoostingRegressor()\n",
    "rf_model = RandomForestRegressor()\n",
    "svr_model = SVR(gamma=0.01)\n",
    "xgb_model = XGBRegressor()\n",
    "\n",
    "# models = [linear_model,ridge_model,gbdt_model,rf_model,svr_model,xgb_model]\n",
    "# models_names = ['linear_model','ridge_model','gbdt_model','rf_model','svr_model','xgb_model']\n",
    "# models_scores_mean = []\n",
    "# st_kflod = StratifiedKFold(n_splits=10,shuffle=False,random_state=0)\n",
    "# for index,model in enumerate(models):\n",
    "#     score = cross_val_score(estimator=model,X=X_train,y=y,scoring='neg_mean_squared_error',cv=10)\n",
    "#     models_scores_mean.append(-score.mean())\n",
    "#     print(f'{models_names[index]}'+'分数:' + f'{score}'+'平均分:'+f'{-score.mean()}')\n",
    "#     print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:59.128Z"
    }
   },
   "outputs": [],
   "source": [
    "data_ino.项目名称.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:59.130Z"
    }
   },
   "outputs": [],
   "source": [
    "age = data_ino.groupby(\"病人ID\")[\"年龄\"].min()\n",
    "# age = age.value_counts()\n",
    "# age = age.unstack()\n",
    "# type(age)\n",
    "\n",
    "# data.top(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:59.131Z"
    }
   },
   "outputs": [],
   "source": [
    "# DataFrame(data,index=[0])\n",
    "\n",
    "# data[\"体检总结\"]\n",
    "\n",
    "# data.to_pickle('diag_all.pkl')\n",
    "check = data.groupby(\"病人ID\")['诊断类型'].value_counts()\n",
    "# check.fillna(0)\n",
    "check_res = check.unstack().fillna(0) #.describe()\n",
    "# check_res.apply(lambda x: x['label'] = 0 if x['疾病诊断'] > 0 else 1)\n",
    "check_res['label'] = np.where(check_res['阳性体征']==0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:59.134Z"
    }
   },
   "outputs": [],
   "source": [
    "check_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机病人ID，检查data_ino和data，分别是检查结果和诊断结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-07-15T01:49:59.143Z"
    }
   },
   "outputs": [],
   "source": [
    "ID = tuple(data_ino.病人ID)\n",
    "sample_ID = random.sample(ID, 1)\n",
    "# sample = random.sample(data, 5)\n",
    "sample_ID\n",
    "\n",
    "# sample_ID\n",
    "# sample_ID = list(sample_ID)\n",
    "sample_diag = data[data.病人ID.isin(sample_ID)]\n",
    "sample_diag\n",
    "sample_ino = data_ino[data_ino.病人ID.isin(sample_ID)]\n",
    "\n",
    "sample_ino.异常提示.value_counts()\n",
    "sample_ino\n",
    "sample_ino[-((sample_ino.异常提示.isnull()) & (sample_ino.阳性标志.isnull()) & (sample_ino.诊断标志.isnull()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
